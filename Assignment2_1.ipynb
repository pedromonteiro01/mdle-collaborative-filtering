{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDLE - Collaborative Filtering Assignment\n",
    "### Exercise 1.1\n",
    "##### Authors: Pedro Duarte 97673, Pedro Monteiro 97484"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from operator import add"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Constants\n",
    "APP_NAME = 'assignment1'\n",
    "MASTER = 'local[*]'\n",
    "\n",
    "# Input Constants\n",
    "INPUT_METADATA_FILE = 'tracks.csv'\n",
    "INPUT_FEATURES_FILE = 'features.csv'\n",
    "\n",
    "# Data Columns\n",
    "COLUMN_TRACK_ID = 'track_id'\n",
    "COLUMN_SET = 'set'\n",
    "COLUMN_SUBSET = 'subset'\n",
    "\n",
    "# Application Constants\n",
    "SUBSET_SMALL_VALUE = 'small'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV files and store the data in Pandas dataframes\n",
    "\n",
    "- tracks: dataset consists of 106,574 music tracks\n",
    "- features: 518 features, corresponding to 7 statistics (mean, standard deviation, skew, kurtosis, median, minimum, maximum) calculated from 74 time-based acoustic characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(INPUT_METADATA_FILE, index_col=0, header=[0, 1]) # has 2 header rows\n",
    "features = pd.read_csv(INPUT_FEATURES_FILE, index_col=0, header=[0, 1, 2]) # has 3 header rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the `tracks` dataframe:\n",
    "\n",
    "- condition checks if the value in the subset column of the set multi-level column index is equal to the string `small`.\n",
    "\n",
    "After that is expected to have only 8000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = tracks[tracks[COLUMN_SET, COLUMN_SUBSET] == SUBSET_SMALL_VALUE]\n",
    "small.shape # get shape of dataframe => 8000 rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python set `ids` which contains the elements of the index of the `small` Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(small.index.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the `rows` from features dataframe that have an index in `ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sm = features.loc[ids]\n",
    "features_sm.shape # get shape of dataframe => (8000, 518)\n",
    "                  # should be 8000 tracks and 518 features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the StandardScaler, from scikit-learn, to standardize the values of `features_sm` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_sm.values # extracts the values from the features dataframe \n",
    "X = StandardScaler().fit(X).transform(X) # X standardization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration and Initialization of Spark\n",
    "\n",
    "- Parameters:\n",
    "    - `APP_NAME` (string): the name of the Spark application\n",
    "    - `MASTER` (string): the URL of the Spark master node\n",
    "<br></br>\n",
    "- Returns:\n",
    "    - `sc` (SparkContext): the Spark context for the given application and master\n",
    "    - `spark` (SparkSession): the Spark session for the given application and master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(APP_NAME).setMaster(MASTER)\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME).master(MASTER).getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Agglomerative Clustering on the small dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {} # dictionary to save metric results\n",
    "\n",
    "for k in range(8, 17):\n",
    "    clusters = AgglomerativeClustering(n_clusters=k).fit_predict(X)\n",
    "\n",
    "    # get the clusters separated\n",
    "    clusters_separated = [X[clusters == i] for i in range(k)]\n",
    "\n",
    "    # create each centroid with the mean of all cluster points\n",
    "    centroids = [cluster.mean(axis=0) for cluster in clusters_separated]\n",
    "\n",
    "    # calculate radius with euclidian distance between all points and the centroid\n",
    "    # radius is the max distance\n",
    "    radius = [max(np.linalg.norm(p - centroids[i]) for p in clusters_separated[i]) for i in range(k)]\n",
    "\n",
    "    # calculate diameter, being the max distance between all points in the same cluster\n",
    "    diameter = [np.max(pairwise_distances(cluster)) for cluster in clusters_separated]\n",
    "\n",
    "    # calculate density with radius, checking if radius is not 0\n",
    "    density_r = [len(clusters_separated[i]) / (radius[i]**2) if radius[i] != 0 else math.inf for i in range(k)]\n",
    "    # calculate density with diameter, checking if diameter is not 0\n",
    "    density_d = [len(clusters_separated[i]) / (diameter[i]**2) if diameter[i] != 0 else math.inf for i in range(k)]\n",
    "\n",
    "    # save results on a dictionary to be used later\n",
    "    results[k] = {\n",
    "        'centroids': centroids,\n",
    "        'radius': radius,\n",
    "        'diameter': diameter,\n",
    "        'density_r': density_r,\n",
    "        'density_d': density_d,\n",
    "    }\n",
    "\n",
    "    print(f'For k = {k}:')\n",
    "    print('Radius:', radius)\n",
    "    print('Diameter:', diameter)\n",
    "    print('Density (r2):', density_r)\n",
    "    print('Density (d2):', density_d)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Scatter Plots with the density r² and d² values for each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(results.keys())\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(45)\n",
    "fig.set_animated(True)\n",
    "fig.subplots_adjust(hspace=.3)\n",
    "\n",
    "for i in range(len(ks)):\n",
    "  k = ks[i]\n",
    "\n",
    "  # for both radius and diameter check if there are densities that are inf and remove (add to invalid idx)\n",
    "  invalid_idxs = [i for i in range(len(results[k]['radius'])) if results[k]['density_r'][i] == math.inf]\n",
    "  radius_results = [results[k]['radius'][i] for i in range(len(results[k]['radius'])) if i not in invalid_idxs]\n",
    "  density_r_results = [results[k]['density_r'][i] for i in range(len(results[k]['density_r'])) if i not in invalid_idxs]\n",
    "\n",
    "  invalid_idxs = [i for i in range(len(results[k]['diameter'])) if results[k]['density_d'][i] == math.inf]\n",
    "  diameter_results = [results[k]['diameter'][i] for i in range(len(results[k]['diameter'])) if i not in invalid_idxs]\n",
    "  density_d_results = [results[k]['density_d'][i] for i in range(len(results[k]['density_d'])) if i not in invalid_idxs]\n",
    "\n",
    "  # plot density r² for each k\n",
    "  sub_r = fig.add_subplot(len(ks), 2, 2*i+1)\n",
    "  sub_r.scatter(radius_results, density_r_results)\n",
    "  sub_r.set_xlabel('Radius')\n",
    "  sub_r.set_ylabel('Density (r**2)')\n",
    "  sub_r.set_title(f'For k = {k}')\n",
    "  sub_r.set_xlim([0, 200])\n",
    "  sub_r.set_ylim([0, 1])\n",
    "\n",
    "  # plot density d² for each k\n",
    "  sub_d = fig.add_subplot(len(ks), 2, 2*i+2)\n",
    "  sub_d.scatter(diameter_results, density_d_results)\n",
    "  sub_d.set_xlabel('Diameter')\n",
    "  sub_d.set_ylabel('Density (d**2)')\n",
    "  sub_d.set_title(f'For k = {k}')\n",
    "  sub_d.set_xlim([0, 200])\n",
    "  sub_d.set_ylim([0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Scatter Plots for the mean density (r² and d²) for each k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(results.keys())\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "fig.set_animated(True)\n",
    "\n",
    "valid_r_ds = { k: [d for d in results[k]['density_r'] if d != math.inf] for k in ks } # get density r² values (remove inf)\n",
    "valid_d_ds = { k: [d for d in results[k]['density_d'] if d != math.inf] for k in ks } # get density d² values (remove inf)\n",
    "\n",
    "sub_r = fig.add_subplot(1, 2, 1)\n",
    "sub_r.scatter(ks, [sum(valid_r_ds[k])/len(valid_r_ds[k]) for k in ks]) # get the mean density r²\n",
    "sub_r.set_xlabel('k')\n",
    "sub_r.set_ylabel('Density (r**2)')\n",
    "sub_r.set_title(f'Density (r²) by K')\n",
    "\n",
    "sub_d = fig.add_subplot(1, 2, 2)\n",
    "sub_d.scatter(ks, [sum(valid_d_ds[k])/len(valid_d_ds[k]) for k in ks]) # get the mean density d²\n",
    "sub_d.set_xlabel('k')\n",
    "sub_d.set_ylabel('Density (d**2)')\n",
    "sub_d.set_title(f'Density (d²) by K')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that calculates the Mahalanobis distance between two points using the inverse covariance matrix, according to the formula:\n",
    "            \n",
    "- d(x, c) = d ∑ i=1 √(xi - ci/σi)²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(x, y, inv_cov):\n",
    "    diff = (x - y) / np.sqrt(np.diag(inv_cov))\n",
    "    return np.sqrt(np.dot(diff, diff))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the BFR algorithm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "def bfr(dataset, k, threshold):\n",
    "    # get previous k centroids, defined with AglomerativeClustering\n",
    "    centroids = np.array(results[k]['centroids'])\n",
    "\n",
    "    # get the inverse of the covariance matrix\n",
    "    inv_cov_matrix = np.linalg.inv(np.cov(dataset.T)) # np.cov(dataset.T) -> covariance matrix\n",
    "\n",
    "    # assign each point to the nearest centroid using Mahalanobis Distance\n",
    "    centroid_distances = [([mahalanobis_distance(point, centroid, inv_cov_matrix) \n",
    "                            for centroid in centroids], point) \n",
    "                            for point in dataset]\n",
    "    \n",
    "    # assign to the cluster only the points that are below the distance threshold\n",
    "    centroid_distances = [np.argmin(distances) \n",
    "                          if np.min(distances) < threshold*np.std(point) \n",
    "                          else None \n",
    "                          for distances, point in centroid_distances]\n",
    "    \n",
    "    assignments = np.array(centroid_distances)\n",
    "    centroids = np.array([dataset[assignments == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "    return centroids, assignments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `StandardScaler` from scikit-learn to complete dataset standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = features.values # get complete dataset values\n",
    "X_full = StandardScaler().fit(X_full).transform(X_full) # values standardization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We choose k=8**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the BFR algorithm, previously created <br>\n",
    "Parameters:\n",
    "- `X_full`: dataset values\n",
    "- `k`: number of clusters\n",
    "- `threshold`: factor to be applied to standard deviation to decide which points belong to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=8\n",
    "centroids, cluster_idxs = bfr(X_full, k, 30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to plot a bar chart of the music genres distribution for a given cluster <br>\n",
    "Parameters:\n",
    "- `ax`: matplotlib axis object representing the subplot where the chart will be drawn\n",
    "- `clusterid`:  integer representing the ID of the cluster to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genres_chart_info(ax, clusterid):\n",
    "  # retrieve tracks indices that belong to the specific cluster\n",
    "  cluster_ids = features[cluster_idxs == clusterid].index.to_list() \n",
    "\n",
    "  # remove empty genres\n",
    "  cluster_genres = tracks.loc[cluster_ids]['track', 'genre_top'].dropna().tolist()\n",
    "\n",
    "  # count the occurrences of each genre in the list\n",
    "  cluster_genres = sc.parallelize(cluster_genres).map(lambda v: (v, 1)).reduceByKey(add).collectAsMap()\n",
    "\n",
    "  # sort genres to plot first the genres with more items\n",
    "  sorted_genres = {k: v for k, v in sorted(cluster_genres.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "  ax.bar([str(key) for key in sorted_genres.keys()], sorted_genres.values())\n",
    "  ax.set_xticklabels([str(key) for key in cluster_genres.keys()], rotation=90) # rotate x-labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the genres plots using the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(35)\n",
    "fig.set_animated(True)\n",
    "fig.subplots_adjust(hspace=.3)\n",
    "\n",
    "k = 8 # number of clusters choosen\n",
    "\n",
    "for i in range(k):\n",
    "  ax = fig.add_subplot(math.ceil(k/2), 2, i+1)\n",
    "  plot_genres_chart_info(ax, i)\n",
    "  ax.set_ylim([0, 5000])\n",
    "  ax.set_xlabel('Genre')\n",
    "  ax.set_ylabel('Amount')\n",
    "  ax.set_title(f'Cluster {i}')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
