{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from operator import add\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Constants\n",
    "APP_NAME = 'assignment1'\n",
    "MASTER = 'local[*]'\n",
    "\n",
    "#random hyper planes\n",
    "# Data Columns\n",
    "COLUMN_USER_ID = 'userId'\n",
    "COLUMN_MOVIE_ID = 'movieId'\n",
    "COLUMN_RATING = 'rating'\n",
    "COLUMN_TIMESTAMP = 'timestamp'\n",
    "\n",
    "# Input Constants\n",
    "MOVIES_INPUT_FILE = 'movies.csv'\n",
    "TAGS_INPUT_FILE = 'tags.csv'\n",
    "RATINGS_INPUT_FILE = 'ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 23:42:28 WARN Utils: Your hostname, pedro-duarte resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp2s0)\n",
      "23/05/04 23:42:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 23:42:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/04 23:42:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(APP_NAME).setMaster(MASTER)\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME).master(MASTER).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_matrix(dataset):\n",
    "    return dataset.pivot(index=COLUMN_MOVIE_ID, columns=COLUMN_USER_ID, values=COLUMN_RATING).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_ratings(dataset):\n",
    "    X = dataset.values\n",
    "    X = StandardScaler().fit(X).transform(X)\n",
    "\n",
    "    return AgglomerativeClustering(n_clusters=None, distance_threshold=200).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(item_matrix, clusters, user_id, movie_id):\n",
    "    if movie_id not in item_matrix.index.to_list(): return 0\n",
    "\n",
    "    movie_idx = item_matrix.index.get_loc(movie_id)\n",
    "    movie_to_predict = item_matrix.loc[movie_id]\n",
    "\n",
    "    similar_movies = item_matrix[clusters == clusters[movie_idx]]\n",
    "\n",
    "    if user_id not in similar_movies.columns.to_list(): return movie_to_predict.mean()\n",
    "    similar_movies = similar_movies[similar_movies[user_id] != 0]\n",
    "\n",
    "    distances = np.dot(movie_to_predict, similar_movies.T)/(np.linalg.norm(movie_to_predict)*np.linalg.norm(similar_movies.T))\n",
    "    \n",
    "    user_ratings = similar_movies.get(user_id)\n",
    "\n",
    "    if user_ratings is None: return movie_to_predict.mean()\n",
    "\n",
    "    ratings_product = np.dot(user_ratings, distances).sum()\n",
    "    user_ratings_distance_total = distances.sum()\n",
    "\n",
    "    if user_ratings_distance_total == 0: return movie_to_predict.mean()\n",
    "\n",
    "    rating_prediction = ratings_product/user_ratings_distance_total\n",
    "\n",
    "    return rating_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.020764511562058"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = create_item_matrix(ratings)\n",
    "clusters = cluster_ratings(ds)\n",
    "\n",
    "predict_rating(ds, clusters, 416, 319)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count = ratings.shape[0]\n",
    "\n",
    "ratings_test_count = math.ceil(ratings_count*.1)\n",
    "\n",
    "# Shuffle\n",
    "ratings = ratings.sample(frac = 1)\n",
    "\n",
    "# Set 10% of ratings for testing\n",
    "ratings_test = ratings[ratings_test_count:]\n",
    "ratings_train = ratings[:ratings_test_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_item_matrix(ratings_train)\n",
    "train_clusters = cluster_ratings(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 23:43:03 WARN TaskSetManager: Stage 0 contains a task of very large size (1371 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation: 22.58084157562842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deviations = sc.parallelize(ratings_test.values) \\\n",
    "  .map(lambda v: predict_rating(train_ds, train_clusters, v[0], v[1])) \\\n",
    "  .reduce(add)\n",
    "\n",
    "print(\"Deviation:\", deviations/ratings_test_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
