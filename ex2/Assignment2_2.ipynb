{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDLE - Collaborative Filtering Assignment\n",
    "### Exercise 2\n",
    "##### Authors: Pedro Duarte 97673, Pedro Monteiro 97484"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from operator import add\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Constants\n",
    "APP_NAME = 'assignment1'\n",
    "MASTER = 'local[*]'\n",
    "\n",
    "#random hyper planes\n",
    "# Data Columns\n",
    "COLUMN_USER_ID = 'userId'\n",
    "COLUMN_MOVIE_ID = 'movieId'\n",
    "COLUMN_RATING = 'rating'\n",
    "COLUMN_TIMESTAMP = 'timestamp'\n",
    "\n",
    "# Input Constants\n",
    "MOVIES_INPUT_FILE = 'movies.csv'\n",
    "TAGS_INPUT_FILE = 'tags.csv'\n",
    "RATINGS_INPUT_FILE = 'ratings.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration and Initialization of Spark\n",
    "\n",
    "- Parameters:\n",
    "    - `APP_NAME` (string): the name of the Spark application\n",
    "    - `MASTER` (string): the URL of the Spark master node\n",
    "<br></br>\n",
    "- Returns:\n",
    "    - `sc` (SparkContext): the Spark context for the given application and master\n",
    "    - `spark` (SparkSession): the Spark session for the given application and master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 23:42:28 WARN Utils: Your hostname, pedro-duarte resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlp2s0)\n",
      "23/05/04 23:42:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 23:42:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/04 23:42:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(APP_NAME).setMaster(MASTER)\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.appName(APP_NAME).master(MASTER).getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ratings CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to return a matrix of items (movies) with user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_matrix(dataset):\n",
    "    return dataset.pivot(index=COLUMN_MOVIE_ID, columns=COLUMN_USER_ID, values=COLUMN_RATING).fillna(0)\n",
    "                                                                            # missing values are filled with 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that clusters the ratings in a given dataset using Agglomerative Clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_ratings(dataset):\n",
    "    X = dataset.values # get dataset values\n",
    "    X = StandardScaler().fit(X).transform(X) # standardize X\n",
    "\n",
    "    return AgglomerativeClustering(n_clusters=None, distance_threshold=200).fit_predict(X) # apply Agglomerative Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the rating that a given user would give to a given movie, based on the user's ratings of similar movies and the similarity of those movies to the given movie, using a collaborative filtering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(item_matrix, clusters, user_id, movie_id):\n",
    "    if movie_id not in item_matrix.index.to_list(): return 0 # check if the movie_id is present in the item_matrix\n",
    "\n",
    "    movie_idx = item_matrix.index.get_loc(movie_id) # get movie index\n",
    "    movie_to_predict = item_matrix.loc[movie_id] # retrieve movie_id row\n",
    "\n",
    "    similar_movies = item_matrix[clusters == clusters[movie_idx]] #  select all movies in the same cluster as the movie_id\n",
    "\n",
    "    # check if user_id is present in the similar_movies column\n",
    "    if user_id not in similar_movies.columns.to_list(): return movie_to_predict.mean() \n",
    "\n",
    "    # remove any movies that the user has not rated\n",
    "    similar_movies = similar_movies[similar_movies[user_id] != 0]\n",
    "\n",
    "    # calculate cosine similarity between movie_to_predict and all the movies in similar_movies\n",
    "    distances = np.dot(movie_to_predict, similar_movies.T)/(np.linalg.norm(movie_to_predict)*np.linalg.norm(similar_movies.T))\n",
    "    \n",
    "    user_ratings = similar_movies.get(user_id) # get user ratings\n",
    "\n",
    "    if user_ratings is None: return movie_to_predict.mean() # check if user_ratings is None => return the mean rating\n",
    "\n",
    "    # calculate weighted sum of the user ratings for the similar movies using the similarity scores as weights\n",
    "    ratings_product = np.dot(user_ratings, distances).sum()\n",
    "    user_ratings_distance_total = distances.sum()\n",
    "\n",
    "    if user_ratings_distance_total == 0: return movie_to_predict.mean()\n",
    "\n",
    "    # calculate final rating prediction by dividing the weighted sum of the ratings by the sum of the similarity scores\n",
    "    rating_prediction = ratings_product/user_ratings_distance_total\n",
    "\n",
    "    return rating_prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a rating prediction for user 416 and movie 319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.020764511562058"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = create_item_matrix(ratings)\n",
    "clusters = cluster_ratings(ds)\n",
    "\n",
    "predict_rating(ds, clusters, 416, 319)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split ratings dataset into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count = ratings.shape[0] # number of rows\n",
    "\n",
    "ratings_test_count = math.ceil(ratings_count*.1) # number of ratings that will be used for testing\n",
    "\n",
    "# shuffle the ratings rows dataset randomly\n",
    "ratings = ratings.sample(frac = 1)\n",
    "\n",
    "# set 10% of ratings for testing\n",
    "ratings_test = ratings[ratings_test_count:]\n",
    "ratings_train = ratings[:ratings_test_count]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an item matrix and apply clustering to the training data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_item_matrix(ratings_train)\n",
    "train_clusters = cluster_ratings(train_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the deviation between predicted and actual ratings on the testing subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 23:43:03 WARN TaskSetManager: Stage 0 contains a task of very large size (1371 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation: 22.58084157562842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deviations = sc.parallelize(ratings_test.values) \\\n",
    "  .map(lambda v: predict_rating(train_ds, train_clusters, v[0], v[1])) \\\n",
    "  .reduce(add)\n",
    "\n",
    "print(\"Deviation:\", deviations/ratings_test_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
